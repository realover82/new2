import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import altair as alt

# ê° CSV ë¶„ì„ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
from csv2 import read_csv_with_dynamic_header, analyze_data
from csv_Fw import read_csv_with_dynamic_header_for_Fw, analyze_Fw_data
from csv_RfTx import read_csv_with_dynamic_header_for_RfTx, analyze_RfTx_data
from csv_Semi import read_csv_with_dynamic_header_for_Semi, analyze_Semi_data
from csv_Batadc import read_csv_with_dynamic_header_for_Batadc, analyze_Batadc_data

def display_analysis_result(analysis_key, file_name, props):
    """ session_stateì— ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ Streamlitì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜ """
    if st.session_state.analysis_results[analysis_key] is None:
        st.error("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # === ìˆ˜ì •ëœ ë¶€ë¶„ 1: analysis_data ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€ ===
    if st.session_state.analysis_data[analysis_key] is None:
        st.error("ë°ì´í„° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¶„ì„ í•¨ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
        
    summary_data, all_dates = st.session_state.analysis_data[analysis_key]
    df_raw = st.session_state.analysis_results[analysis_key]
    
    # ë‘ ë²ˆì§¸ ìˆ˜ì •: all_datesê°€ ì—¬ì „íˆ Noneì¼ ê²½ìš°ë¥¼ ì²˜ë¦¬
    if all_dates is None:
        st.error("ë°ì´í„° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    # =======================================================
    
    st.markdown(f"### '{file_name}' ë¶„ì„ ë¦¬í¬íŠ¸")

    # === ìˆ˜ì •ëœ ë¶€ë¶„ 2: í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ì¶”ê°€ ===
    required_columns = [props['jig_col'], props['timestamp_col']]
    missing_columns = [col for col in required_columns if col not in df_raw.columns]
    
    if missing_columns:
        st.error(f"ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_columns)}. íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    # =======================================================
    
    # --- ê¸°ë³¸ í•„í„°ë§ (Jig, ë‚ ì§œ ë²”ìœ„) ---
    st.subheader("ê¸°ë³¸ í•„í„°ë§")
    filter_col1, filter_col2, filter_col3 = st.columns(3)
    
    with filter_col1:
        jig_list = sorted(df_raw[props['jig_col']].dropna().unique().tolist()) if props['jig_col'] in df_raw.columns else []
        selected_jig = st.selectbox("PC(Jig) ì„ íƒ", ["ì „ì²´"] + jig_list, key=f"select_{analysis_key}")
    
    if not all_dates:
        st.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    min_date, max_date = min(all_dates), max(all_dates)
    with filter_col2:
        start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", min_value=min_date, max_value=max_date, value=min_date, key=f"start_date_{analysis_key}")
    with filter_col3:
        end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", min_value=min_date, max_value=max_date, value=max_date, key=f"end_date_{analysis_key}")

    if start_date > end_date:
        st.error("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return

    filtered_dates = [d for d in all_dates if start_date <= d <= end_date]
    if not filtered_dates:
        st.warning("ì„ íƒëœ ë‚ ì§œ ë²”ìœ„ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.write(f"**ë¶„ì„ ì‹œê°„**: {st.session_state.analysis_time[analysis_key]}")
    st.markdown("---")

    # --- ë°ì´í„° ì§‘ê³„ ---
    jigs_to_display = jig_list if selected_jig == "ì „ì²´" else [selected_jig]
    
    daily_aggregated_data = {}
    for date_obj in all_dates:
        daily_totals = {key: 0 for key in ['total_test', 'pass', 'false_defect', 'true_defect', 'fail']}
        for jig in jigs_to_display:
            data_point = summary_data.get(jig, {}).get(date_obj.strftime('%Y-%m-%d'))
            if data_point:
                for key in daily_totals:
                    daily_totals[key] += data_point.get(key, 0)
        daily_aggregated_data[date_obj] = daily_totals

    # --- ìš”ì•½ (ë‚ ì§œ ë²”ìœ„ ìš”ì•½ í…Œì´ë¸”) ---
    st.subheader("ê¸°ê°„ ìš”ì•½")
    
    if filtered_dates:
        # ì¼ë³„ ì§‘ê³„ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        summary_df_data = {
            'ë‚ ì§œ': [d.strftime('%m-%d') for d in filtered_dates],
            'ì´ í…ŒìŠ¤íŠ¸ ìˆ˜': [daily_aggregated_data.get(d, {}).get('total_test', 0) for d in filtered_dates],
            'PASS': [daily_aggregated_data.get(d, {}).get('pass', 0) for d in filtered_dates],
            'ê°€ì„±ë¶ˆëŸ‰': [daily_aggregated_data.get(d, {}).get('false_defect', 0) for d in filtered_dates],
            'ì§„ì„±ë¶ˆëŸ‰': [daily_aggregated_data.get(d, {}).get('true_defect', 0) for d in filtered_dates],
            'FAIL': [daily_aggregated_data.get(d, {}).get('fail', 0) for d in filtered_dates]
        }
        summary_df = pd.DataFrame(summary_df_data).set_index('ë‚ ì§œ')
        # í–‰/ì—´ì„ ë°”ê¿”ì„œ í‘œì‹œ (transpose)
        st.dataframe(summary_df.transpose())
    else:
        st.info("ì„ íƒëœ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # --- ì¼ë³„ ì¶”ì´ ê·¸ë˜í”„ ---
    st.subheader("ì¼ìë³„ ë¶ˆëŸ‰ ì¶”ì´")
    chart_mode_key = f'chart_mode_{analysis_key}'
    if chart_mode_key not in st.session_state:
        st.session_state[chart_mode_key] = 'bar'

    graph_cols = st.columns(2)
    with graph_cols[0]:
        if st.button("êº¾ì€ì„  ê·¸ë˜í”„", key=f"line_chart_btn_{analysis_key}"):
            st.session_state[chart_mode_key] = 'line'
    with graph_cols[1]:
        if st.button("ë§‰ëŒ€ ê·¸ë˜í”„", key=f"bar_chart_btn_{analysis_key}"):
            st.session_state[chart_mode_key] = 'bar'
    
    # 1. ëª¨ë“  raw ë°ì´í„°ì—ì„œ í•„í„°ë§
    filtered_df_for_chart = df_raw[
        (df_raw[props['jig_col']].isin(jigs_to_display)) &
        (df_raw[props['timestamp_col']].dt.date.isin(filtered_dates))
    ].copy()
    
    # 'PassStatusNorm'ì´ 'X'ì¸ ë°ì´í„°ë§Œ ë‚¨ê¹ë‹ˆë‹¤. (PASS ë°ì´í„° ì œì™¸)
    filtered_df_for_chart = filtered_df_for_chart[filtered_df_for_chart['PassStatusNorm'] == 'X']
    # PassStatusNorm ì»¬ëŸ¼ì„ ì¶”ê°€í•œ ì½”ë“œ ë°”ë¡œ ì•„ë˜ì— ì‚½ì…
    if 'PassStatusNorm' not in filtered_df_for_chart.columns:
        print("ğŸš¨ğŸš¨ ì˜¤ë¥˜: PassStatusNorm ì»¬ëŸ¼ì´ DataFrameì— ì—†ìŠµë‹ˆë‹¤! ğŸš¨ğŸš¨")
    else:
        print("âœ… ì„±ê³µ: PassStatusNorm ì»¬ëŸ¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
        print("ê°’ ì˜ˆì‹œ:", filtered_df_for_chart['PassStatusNorm'].head())

    # # 2. ì‹œê°„ë³„ ë°ì´í„° ì§‘ê³„
    # if not filtered_df_for_chart.empty:
    #     # ê°€ì„±ë¶ˆëŸ‰/ì§„ì„±ë¶ˆëŸ‰ ë¶„ë¦¬ë¥¼ ìœ„í•´ SNumberì˜ PASS ê¸°ë¡ì„ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
    #     jig_pass_history = df_raw[df_raw['PassStatusNorm'] == 'O'].groupby(props['jig_col'])['SNumber'].unique().apply(set).to_dict()
    #     current_jig_passed_sns = jig_pass_history.get(selected_jig, set()) if selected_jig != "ì „ì²´" else set(df_raw[df_raw['PassStatusNorm'] == 'O']['SNumber'].unique())
        
    #     # ê°€ì„±/ì§„ì„± ë¶ˆëŸ‰ ì»¬ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
    #     filtered_df_for_chart['ë¶ˆëŸ‰ ìœ í˜•'] = filtered_df_for_chart['SNumber'].apply(
    #         lambda sn: 'ê°€ì„±ë¶ˆëŸ‰' if sn in current_jig_passed_sns else 'ì§„ì„±ë¶ˆëŸ‰'
    #     )

    #     # ì‹œê°„ëŒ€ë³„/ìœ í˜•ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  ê±´ìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤.
    #     chart_data_list = filtered_df_for_chart.groupby([
    #         pd.Grouper(key=props['timestamp_col'], freq='H'),
    #         'ë¶ˆëŸ‰ ìœ í˜•'
    #     ]).size().reset_index(name='ìˆ˜ëŸ‰')
        
    #     # 'datetime' ì»¬ëŸ¼ì˜ ë‚ ì§œ ë¶€ë¶„ê³¼ ì‹œê°„ ë¶€ë¶„ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    #     chart_data_list['ë‚ ì§œ'] = chart_data_list[props['timestamp_col']].dt.date
    #     chart_data_list['ì‹œê°„'] = chart_data_list[props['timestamp_col']].dt.time

    # if not filtered_df_for_chart.empty:
    #     chart_df_melted = chart_data_list.rename(columns={props['timestamp_col']: 'datetime'})

    #     # Altair ì°¨íŠ¸ ìƒì„±
    #     base = alt.Chart(chart_df_melted).encode(
    #         x=alt.X('ì‹œê°„:T', axis=alt.Axis(title='ì‹œê°„', format='%H:%M')),
    #         y=alt.Y('ìˆ˜ëŸ‰:Q', axis=alt.Axis(title='ë¶ˆëŸ‰ ê±´ìˆ˜'))
    #     ).properties(
    #         title='ì‹œê°„ëŒ€ë³„ ë¶ˆëŸ‰ ê±´ìˆ˜ ì¶”ì´'
    #     )
        
    #     # ë¼ì¸ ë˜ëŠ” ë§‰ëŒ€ ì°¨íŠ¸
    #     if st.session_state[chart_mode_key] == 'line':
    #         chart = base.mark_line(point=True).encode(
    #             color=alt.Color('ë¶ˆëŸ‰ ìœ í˜•', legend=alt.Legend(title="ë¶ˆëŸ‰ ìœ í˜•")),
    #             tooltip=['datetime:T', 'ë¶ˆëŸ‰ ìœ í˜•', 'ìˆ˜ëŸ‰']
    #         )
    #     else: # 'bar'
    #         chart = base.mark_bar().encode(
    #             color=alt.Color('ë¶ˆëŸ‰ ìœ í˜•', legend=alt.Legend(title="ë¶ˆëŸ‰ ìœ í˜•")),
    #             tooltip=['datetime:T', 'ë¶ˆëŸ‰ ìœ í˜•', 'ìˆ˜ëŸ‰']
    #         )
        
    #     # ë‚ ì§œë³„ë¡œ ê·¸ë˜í”„ë¥¼ ë¶„í• 
    #     final_chart = chart.facet(
    #         column=alt.Column('ë‚ ì§œ:N', header=alt.Header(titleOrient="bottom", labelOrient="bottom"))
    #     ).resolve_scale(
    #         x='independent',
    #         y='independent'
    #     )

    #     st.altair_chart(final_chart, use_container_width=False) # container_widthë¥¼ Falseë¡œ ì„¤ì •í•˜ì—¬ ê°€ë¡œ ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•˜ê²Œ í•¨
    # else:
    #     st.info("ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # --- ìƒì„¸ ë‚´ì—­ (ì¼ë³„) ---
    st.subheader("ìƒì„¸ ë‚´ì—­ (ì¼ë³„)")
    
    # 1. ìƒì„¸ ë‚´ì—­ ë³´ê¸° ì œì–´ìš© ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if f'show_details_{analysis_key}' not in st.session_state:
        st.session_state[f'show_details_{analysis_key}'] = False

    # 2. ìƒì„¸ ë‚´ì—­ ì¡°íšŒ ë²„íŠ¼ ì¶”ê°€
    if st.button("ìƒì„¸ ë‚´ì—­ ì¡°íšŒ", key=f"show_details_btn_{analysis_key}"):
        st.session_state[f'show_details_{analysis_key}'] = True
        # ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê¸°ë³¸ì ìœ¼ë¡œ 'ë¶ˆëŸ‰ë§Œ ë³´ê¸°' ëª¨ë“œë¡œ ì„¤ì •
        st.session_state[f'detail_mode_{analysis_key}'] = 'defects'

    # 3. ë²„íŠ¼ì´ ëˆŒë¦¬ë©´ ìƒì„¸ ë‚´ì—­ í‘œì‹œ
    if st.session_state[f'show_details_{analysis_key}']:
        # ì„¸ì…˜ ìƒíƒœì— ìƒì„¸ ë³´ê¸° ëª¨ë“œë¥¼ ì €ì¥í•  ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        if f'detail_mode_{analysis_key}' not in st.session_state:
            st.session_state[f'detail_mode_{analysis_key}'] = 'all'

        # ìƒì„¸ ë³´ê¸° ëª¨ë“œ ë²„íŠ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.
        detail_col1, detail_col2, detail_col3 = st.columns(3)
        with detail_col1:
            if st.button("ì „ì²´ ë³´ê¸°", key=f"detail_all_{analysis_key}"):
                st.session_state[f'detail_mode_{analysis_key}'] = 'all'
        with detail_col2:
            if st.button("ë¶ˆëŸ‰ë§Œ ë³´ê¸°", key=f"detail_defects_{analysis_key}"):
                st.session_state[f'detail_mode_{analysis_key}'] = 'defects'
        with detail_col3:
            if st.button("PASSë§Œ ë³´ê¸°", key=f"detail_pass_{analysis_key}"):
                st.session_state[f'detail_mode_{analysis_key}'] = 'pass'
        
        # í˜„ì¬ ìƒì„¸ ë³´ê¸° ëª¨ë“œì— ë”°ë¼ í‘œì‹œí•  ì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        current_mode = st.session_state[f'detail_mode_{analysis_key}']
        
        for date_obj in filtered_dates:
            st.markdown(f"**{date_obj.strftime('%Y-%m-%d')}**")
            
            for jig in jigs_to_display:
                data_point = summary_data.get(jig, {}).get(date_obj.strftime('%Y-%m-%d'))
                if not data_point or data_point.get('total_test', 0) == 0:
                    continue

                st.markdown(f"**PC(Jig): {jig}**")
                
                # í˜„ì¬ ëª¨ë“œì— ë”°ë¼ í‘œì‹œí•  ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                if current_mode == 'defects':
                    categories = ['false_defect', 'true_defect']
                    labels = ['ê°€ì„±ë¶ˆëŸ‰', 'ì§„ì„±ë¶ˆëŸ‰']
                elif current_mode == 'pass':
                    categories = ['pass']
                    labels = ['PASS']
                else: # 'all' ë˜ëŠ” íŠ¹ì • ë‚ ì§œ ì„ íƒ
                    categories = ['pass', 'false_defect', 'true_defect', 'fail']
                    labels = ['PASS', 'ê°€ì„±ë¶ˆëŸ‰', 'ì§„ì„±ë¶ˆëŸ‰', 'FAIL']

                for cat, label in zip(categories, labels):
                    full_data_list = data_point.get(f'{cat}_data', [])
                    
                    if not full_data_list:
                        continue

                    count = len(full_data_list)
                    unique_count = len(set(d['SNumber'] for d in full_data_list))

                    expander_title = f"{label} - {count}ê±´ (ì¤‘ë³µê°’ì œê±° SN: {unique_count}ê±´)"
                    
                    with st.expander(expander_title, expanded=False):
                        fields_to_display = st.session_state.field_mapping.get(analysis_key, ['SNumber'])
                        
                        if not fields_to_display:
                            st.info("í‘œì‹œí•  í•„ë“œê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                            continue

                        for item in full_data_list:
                            formatted_fields = [f"{field}: {item.get(field, 'N/A')}" for field in fields_to_display]
                            st.text(", ".join(formatted_fields))
            st.markdown("---")

    # --- DB ì›ë³¸ í™•ì¸ ë° ìƒì„¸ ê²€ìƒ‰ ê¸°ëŠ¥ ---
    st.subheader("DB ì›ë³¸ ìƒì„¸ ê²€ìƒ‰")
    search_col1, search_col2, search_col3 = st.columns([1, 2, 1])
    with search_col1:
        snumber_query = st.text_input("SNumber ê²€ìƒ‰", key=f"snumber_search_{analysis_key}")
    with search_col2:
        all_columns = df_raw.columns.tolist()
        selected_columns = st.multiselect("í‘œì‹œí•  í•„ë“œ(ì—´) ì„ íƒ", all_columns, key=f"col_select_{analysis_key}")
    with search_col3:
        st.write("") 
        st.write("") 
        apply_button = st.button("í•„í„° ì ìš©", key=f"apply_filter_{analysis_key}")

    filter_state_key = f'applied_filters_{analysis_key}'
    if apply_button:
        st.session_state[filter_state_key] = {
            'snumber': snumber_query,
            'columns': selected_columns
        }
    
    applied_filters = st.session_state.get(filter_state_key, {'snumber': '', 'columns': []})

    with st.expander("DB ì›ë³¸ í™•ì¸"):
        df_display = df_raw.copy()
        
        if applied_filters['snumber']:
            query = applied_filters['snumber']
            if 'SNumber' in df_display.columns and pd.api.types.is_string_dtype(df_display['SNumber']):
                df_display = df_display[df_display['SNumber'].str.contains(query, na=False, case=False)]
            else:
                try:
                    df_display = df_display[df_display.apply(lambda row: query.lower() in str(row.values).lower(), axis=1)]
                except Exception:
                    st.warning("SNumber ê²€ìƒ‰ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤.")

        if applied_filters['columns']:
            existing_cols = [col for col in applied_filters['columns'] if col in df_display.columns]
            df_display = df_display[existing_cols]
        
        st.dataframe(df_display)


# ==============================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==============================
def main():
    st.set_page_config(layout="wide")
    st.title("ë¦¬ëª¨ì»¨ ìƒì‚° ë°ì´í„° ë¶„ì„ íˆ´")
    st.markdown("---")

    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = {k: None for k in ['Pcb', 'Fw', 'RfTx', 'Semi', 'Batadc']}
    if 'uploaded_files' not in st.session_state:
        st.session_state.uploaded_files = {k: None for k in ['Pcb', 'Fw', 'RfTx', 'Semi', 'Batadc']}
    if 'analysis_data' not in st.session_state:
        st.session_state.analysis_data = {k: None for k in ['Pcb', 'Fw', 'RfTx', 'Semi', 'Batadc']}
    if 'analysis_time' not in st.session_state:
        st.session_state.analysis_time = {k: None for k in ['Pcb', 'Fw', 'RfTx', 'Semi', 'Batadc']}
    if 'field_mapping' not in st.session_state:
        st.session_state.field_mapping = {}

    tabs = st.tabs(["íŒŒì¼ Pcb ë¶„ì„", "íŒŒì¼ Fw ë¶„ì„", "íŒŒì¼ RfTx ë¶„ì„", "íŒŒì¼ Semi ë¶„ì„", "íŒŒì¼ Batadc ë¶„ì„"])
    tab_map = {
        'Pcb': {'tab': tabs[0], 'reader': read_csv_with_dynamic_header, 'analyzer': analyze_data, 'jig_col': 'PcbMaxIrPwr', 'timestamp_col': 'PcbStartTime'},
        'Fw': {'tab': tabs[1], 'reader': read_csv_with_dynamic_header_for_Fw, 'analyzer': analyze_Fw_data, 'jig_col': 'FwPC', 'timestamp_col': 'FwStamp'},
        'RfTx': {'tab': tabs[2], 'reader': read_csv_with_dynamic_header_for_RfTx, 'analyzer': analyze_RfTx_data, 'jig_col': 'RfTxPC', 'timestamp_col': 'RfTxStamp'},
        'Semi': {'tab': tabs[3], 'reader': read_csv_with_dynamic_header_for_Semi, 'analyzer': analyze_Semi_data, 'jig_col': 'SemiAssyMaxSolarVolt', 'timestamp_col': 'SemiAssyStartTime'},
        'Batadc': {'tab': tabs[4], 'reader': read_csv_with_dynamic_header_for_Batadc, 'analyzer': analyze_Batadc_data, 'jig_col': 'BatadcPC', 'timestamp_col': 'BatadcStamp'}
    }

    for key, props in tab_map.items():
        with props['tab']:
            st.header(f"{key.upper()} ë°ì´í„° ë¶„ì„")
            st.session_state.uploaded_files[key] = st.file_uploader(f"{key.upper()} íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”", type=["csv"], key=f"uploader_{key}")
            
            if st.session_state.uploaded_files[key]:
                if st.button(f"{key.upper()} ë¶„ì„ ì‹¤í–‰", key=f"analyze_{key}"):
                    try:
                        df = props['reader'](st.session_state.uploaded_files[key])
                        
                        if df is None or df.empty:
                            st.error(f"{key.upper()} ë°ì´í„° íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ê±°ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.session_state.analysis_results[key] = None
                            continue
                        
                        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                        if props['jig_col'] not in df.columns or props['timestamp_col'] not in df.columns:
                            st.error(f"ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ ('{props['jig_col']}', '{props['timestamp_col']}')ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.session_state.analysis_results[key] = None
                            continue
                            
                        # íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ ë¡œì§
                        try:
                            df[props['timestamp_col']] = pd.to_datetime(df[props['timestamp_col']], errors='coerce')
                            if df[props['timestamp_col']].isnull().all():
                                st.warning(f"íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {props['timestamp_col']} ì»¬ëŸ¼ì˜ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                                st.session_state.analysis_results[key] = None
                                continue
                        except Exception as e:
                            st.warning(f"íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                            st.session_state.analysis_results[key] = None
                            continue

                        with st.spinner("ë°ì´í„° ë¶„ì„ ë° ì €ì¥ ì¤‘..."):
                            st.session_state.analysis_results[key] = df.copy()
                            st.session_state.analysis_data[key] = props['analyzer'](df)
                            st.session_state.analysis_time[key] = datetime.now().strftime('%Y-%m-%d')
                        st.success("ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        
                    except Exception as e:
                        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        st.session_state.analysis_results[key] = None

                if st.session_state.analysis_results[key] is not None:
                    display_analysis_result(key, st.session_state.uploaded_files[key].name, props)

if __name__ == "__main__":
    main()